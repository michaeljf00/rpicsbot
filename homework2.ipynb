{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOO0pdLKA5KCcHnSJKmou5+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaeljf00/rpicsbot/blob/main/homework2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Homework 2: Ensemble Learning**"
      ],
      "metadata": {
        "id": "8xVCYl9CYONS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1(30 points)**: Implement a Decision Tree Classifier for your classification problem. You may use a built-in package to implement your classifier. Try modifying one or more of the input parameters and describe what changes you notice in your results. Clearly describe how these factors are affecting your output."
      ],
      "metadata": {
        "id": "Xgh4zQ_KjTIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM5wjwlelozi",
        "outputId": "50b356ba-c4cb-40a4-9e34-ac2d21f025f3"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "SEED = 27"
      ],
      "metadata": {
        "id": "tSBHIvgDjgn1"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('drive/MyDrive/cardio_train.csv', sep = ',', header = 0)\n",
        "new_df = df.drop([\"id\"], axis=1)\n",
        "X = new_df.drop(\"cardio\", axis=1).to_numpy()\n",
        "Y = new_df[\"cardio\"].to_numpy() "
      ],
      "metadata": {
        "id": "qpljHfnEkToL"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = new_df.head(10000)\n",
        "new_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RQcyyUVflAkI",
        "outputId": "47a5947b-96e6-4082-94fe-e0c0c3427085"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  alco  \\\n",
              "0   50       2     168    62.0    110     80            1     1      0     0   \n",
              "1   55       1     156    85.0    140     90            3     1      0     0   \n",
              "2   52       1     165    64.0    130     70            3     1      0     0   \n",
              "3   48       2     169    82.0    150    100            1     1      0     0   \n",
              "4   48       1     156    56.0    100     60            1     1      0     0   \n",
              "\n",
              "   active  cardio  \n",
              "0       1       0  \n",
              "1       1       1  \n",
              "2       0       1  \n",
              "3       1       1  \n",
              "4       0       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fea64c2-2b30-4fe2-ad55-acd179e1a289\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>ap_hi</th>\n",
              "      <th>ap_lo</th>\n",
              "      <th>cholesterol</th>\n",
              "      <th>gluc</th>\n",
              "      <th>smoke</th>\n",
              "      <th>alco</th>\n",
              "      <th>active</th>\n",
              "      <th>cardio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>168</td>\n",
              "      <td>62.0</td>\n",
              "      <td>110</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>85.0</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64.0</td>\n",
              "      <td>130</td>\n",
              "      <td>70</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48</td>\n",
              "      <td>2</td>\n",
              "      <td>169</td>\n",
              "      <td>82.0</td>\n",
              "      <td>150</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>56.0</td>\n",
              "      <td>100</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fea64c2-2b30-4fe2-ad55-acd179e1a289')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6fea64c2-2b30-4fe2-ad55-acd179e1a289 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6fea64c2-2b30-4fe2-ad55-acd179e1a289');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=SEED) "
      ],
      "metadata": {
        "id": "eIP-Lm0AmEWH"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treeModel1 =  DecisionTreeClassifier(criterion = 'entropy', random_state=SEED)\n",
        "treeModel1.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ45Qu9iOBpc",
        "outputId": "a3cc10d9-b77d-45ae-f329-374e47f03686"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', random_state=27)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treeModel1.score(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2ONo85Gqi4R",
        "outputId": "7a51f0d7-2c58-4129-e62d-7ff9db120a47"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9769333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treeModel1.score(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzc1hkRMqXTt",
        "outputId": "4f4866ed-f28e-4a86-ef51-4cbe98bb8cc5"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6352"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treeModel2 = DecisionTreeClassifier(criterion = 'gini', min_samples_split=7, random_state=SEED)\n",
        "treeModel2.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2JSj3lnuZMt",
        "outputId": "93da6a38-ff2c-4b36-a88a-38843b38dbc9"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(min_samples_split=7, random_state=27)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treeModel2.score(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnF2EZw-vzfK",
        "outputId": "c8b1f13f-2496-4873-9971-c67c44d3328f"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8857904761904762"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treeModel2.score(X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF2rLZBLv_1R",
        "outputId": "63d0f500-9788-4765-df5a-cdbc9f81613c"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6385714285714286"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I created two decision tree models with diferent values for the paremeters `criterion` and `min_samples_split`. The results from changing these values are very interesting. The first model had 'entropy' as the `criterion`, measuring the quality of the split and it had a default minimum of 2 samples required to split an internal node. The second model had 'gini' as the `criterion` and required a minimum of 7 samples to split an internal node. When scoring both models, the second model had a lower accuracy than first one when taking the trainning set as input. The accuracy of the second model using the test set was slightly higher compared to the first. \n",
        "\n",
        "Gini has a smaller range in impurities compared to entropy which usually leads to choosing better features. Increasing the amount on which a node splits will limit the number of features being considered. This resulted in certain relations between features lost in the training model."
      ],
      "metadata": {
        "id": "7tRJB3qCwKD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2(30 points)**: From the Bagging and Boosting ensemble methods pick any one algorithm from each category. Implement both the algorithms using the same data. Use k-fold cross validation to find the effectiveness \n",
        "of both the models. Comment on the difference/similarity of\n",
        "the results."
      ],
      "metadata": {
        "id": "HhnTJZqA4tyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from numpy import mean, std"
      ],
      "metadata": {
        "id": "aoIv_1Rk5EoQ"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kFoldCrossValAccuracy(model, X, Y, random_state=SEED):\n",
        "  cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=random_state)\n",
        "  n_scores = cross_val_score(model, X, Y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "  print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "id": "ScQmcb52EOHI"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adaBoostModel = AdaBoostClassifier(random_state=SEED)\n",
        "adaBoostModel.fit(X, Y)\n",
        "print(\"~~Adaboost~~\")\n",
        "kFoldCrossValAccuracy(adaBoostModel, X, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWmZ_oVhCjK_",
        "outputId": "a9707f73-91fa-4220-8aec-fb1adb85305e"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~~Adaboost~~\n",
            "Accuracy: 0.730 (0.005)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomForestModel = RandomForestClassifier(random_state=SEED)\n",
        "randomForestModel.fit(X, Y)\n",
        "print(\"~~Random Forest~~\")\n",
        "kFoldCrossValAccuracy(randomForestModel, X, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkVF_xgTI1jT",
        "outputId": "e8ed0459-c7bf-4ca8-a1e2-4367fac27ec8"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~~Random Forest~~\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.706 (0.005)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The boosting method I chose to use was the adaboost classifier. The bagging method that was implemented was random forest. Performance was near identical for both implementation with the AdaBoost model having a higher accuracy by 0.024. The standard deviations for both are the same with low values of 0.005. Both models are at default so most likely the performance of both can be improved by adjusting certain parameters."
      ],
      "metadata": {
        "id": "27DY3dqtLSZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3(40 points)**:  Compare the effectiveness of the three models implemented above. Clearly describe the metric you are using for comparison. Describe (with examples) Why is this metric(metrics) suited/appropriate for the problem at hand? How would a choice of a different\n",
        "metric impact your results? Can you demonstrate that?"
      ],
      "metadata": {
        "id": "KgU4qxaTP1jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score"
      ],
      "metadata": {
        "id": "LiyIoNsNQiB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyzeData(model, X_test=X_test, Y_test=Y_test):\n",
        "  Y_pred = model.predict(X_test)\n",
        "  print(f\"Confusion Matrix: {confusion_matrix(Y_test, Y_pred)}\")\n",
        "  print(f\"Accuracy: {accuracy_score(Y_test, Y_pred)}\")\n",
        "  print(f\"Precision: {precision_score(Y_test, Y_pred)}\\n\")"
      ],
      "metadata": {
        "id": "vFlZSmLlUzw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Default Decision Tree Classifier\n",
        "print(\"Default Decision Tree Classifier: \")\n",
        "analyzeData(treeModel1)\n",
        "\n",
        "# AdaBoost Model\n",
        "print(\"AdaBoost Model:\")\n",
        "analyzeData(adaBoostModel)\n",
        "\n",
        "# Random Forest Model\n",
        "print(\"Random Forest Model:\")\n",
        "analyzeData(randomForestModel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zhHibHNWDhZ",
        "outputId": "36a81ed0-836e-4434-b516-d3f72c6ec87d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Decision Tree Classifier: \n",
            "Confusion Matrix: [[5698 3017]\n",
            " [3367 5418]]\n",
            "Accuracy: 0.6352\n",
            "Precision: 0.6423236514522822\n",
            "\n",
            "AdaBoost Model:\n",
            "Confusion Matrix: [[6976 1739]\n",
            " [2967 5818]]\n",
            "Accuracy: 0.7310857142857143\n",
            "Precision: 0.7698822283975122\n",
            "\n",
            "Random Forest Model:\n",
            "Confusion Matrix: [[8571  144]\n",
            " [ 294 8491]]\n",
            "Accuracy: 0.9749714285714286\n",
            "Precision: 0.98332368268674\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Default Decision Tree K-Fold Cross Validation\n",
        "kFoldCrossValAccuracy(treeModel1, X, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MWILnVNiCfr",
        "outputId": "36d93b75-332f-4345-fed1-2950c423860e"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.640 (0.005)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I utilized the confusion matrix along and compared the measurements of the accuracy and precision of each model. The confuson matrix is a suitable metric to determine the effectiveness of each of these models. It is able to take into account if all classes are being predicted equally well or certain classes are being neglected when evaluating performance. Compared to regular classification accuracy, it is able to give explanation on what type of errors are being made. In the medical field, it is important to understand what errors are being made and to minimize it as much as possible, which makes this metric apporpiate to be used here since the goal is to predict cardiovascular disease.\n",
        "\n",
        "Looking at three models, it is apparent that boosting and bagging was overall beneficial in its use here. AdaBoost outperformed the default decision tree classifier and the Random Forest Model outperformed both with a very high accuracy and precision.\n",
        "\n",
        "If we based the effectiveness of the three models on the cross validation score, then there would be a discrepancy in which model is the most effective. The values calculated in step 2 show that the AdaBoost performed better compared to the Random Forest which contrasts from the order of effectiveness here."
      ],
      "metadata": {
        "id": "Suj9KMr3XDgW"
      }
    }
  ]
}